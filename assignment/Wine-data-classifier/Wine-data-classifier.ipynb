{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline   target  \n",
      "0                          3.92   1065.0  class_0  \n",
      "1                          3.40   1050.0  class_0  \n",
      "2                          3.17   1185.0  class_0  \n",
      "3                          3.45   1480.0  class_0  \n",
      "4                          2.93    735.0  class_0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "df['target'] = pd.Categorical.from_codes(data.target,data.target_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  \n",
      "0                          3.92   1065.0  \n",
      "1                          3.40   1050.0  \n",
      "2                          3.17   1185.0  \n",
      "3                          3.45   1480.0  \n",
      "4                          2.93    735.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.382e+01 1.750e+00 2.420e+00 1.400e+01 1.110e+02 3.880e+00 3.740e+00\n",
      " 3.200e-01 1.870e+00 7.050e+00 1.010e+00 3.260e+00 1.190e+03]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=16)\n",
    "\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6888888888888889\n",
      "0.6888888888888889\n",
      "0.6888888888888889\n",
      "[[15  0  0]\n",
      " [ 2  8  3]\n",
      " [ 2  7  8]]\n"
     ]
    }
   ],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn_model.fit(X_train,y_train)\n",
    "\n",
    "knn_pred = knn_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, knn_pred)\n",
    "\n",
    "precision = precision_score(y_test, knn_pred,average='micro')\n",
    "\n",
    "recall = recall_score(y_test, knn_pred,average='micro')\n",
    "\n",
    "confusion = confusion_matrix(y_test,knn_pred)\n",
    "\n",
    "# What is accuracy? -> Percent of accurate predictions\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "0.9333333333333333\n",
      "0.9333333333333333\n",
      "[[15  0  0]\n",
      " [ 1 11  1]\n",
      " [ 0  1 16]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(max_iter=3000)\n",
    "\n",
    "log_model.fit(X_train,y_train)\n",
    "\n",
    "log_pred = log_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test,log_pred)\n",
    "\n",
    "precision = precision_score(y_test, log_pred,average='micro')\n",
    "\n",
    "recall = recall_score(y_test, log_pred,average='micro')\n",
    "\n",
    "confusion = confusion_matrix(y_test,log_pred)\n",
    "\n",
    "# What is accuracy? -> Percent of accurate predictions\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n",
      "0.9555555555555556\n",
      "0.9555555555555556\n",
      "[[15  0  0]\n",
      " [ 1 12  0]\n",
      " [ 0  1 16]]\n"
     ]
    }
   ],
   "source": [
    "svm_model =   SVC(kernel=\"linear\", C=0.025, random_state=42)\n",
    "\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "# ->  (True Positives + True Negatives) / (True Positives + False Positives + Ture Negatives + False Negatives)\n",
    "accuracy = accuracy_score(y_test,svm_pred )\n",
    "# True Positives / (True Positives + False Positives) \n",
    "precision = precision_score(y_test, svm_pred,average='micro' )\n",
    "# True Positives / (True Positives + False Negatives)\n",
    "recall = recall_score(y_test,svm_pred,average='micro' )\n",
    "\n",
    "confusion = confusion_matrix(y_test,svm_pred )\n",
    "\n",
    "# What is accuracy? -> Percent of accurate predictions\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5777777777777777\n",
      "0.5777777777777777\n",
      "0.5777777777777777\n",
      "[[14  1  0]\n",
      " [ 1 12  0]\n",
      " [ 0 17  0]]\n"
     ]
    }
   ],
   "source": [
    "svm_model =   SVC(kernel=\"poly\", C=0.025, random_state=42)\n",
    "\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "\n",
    "# ->  (True Positives + True Negatives) / (True Positives + False Positives + Ture Negatives + False Negatives)\n",
    "accuracy = accuracy_score(y_test,svm_pred )\n",
    "# True Positives / (True Positives + False Positives) \n",
    "precision = precision_score(y_test, svm_pred,average='micro' )\n",
    "# True Positives / (True Positives + False Negatives)\n",
    "recall = recall_score(y_test,svm_pred,average='micro' )\n",
    "\n",
    "confusion = confusion_matrix(y_test,svm_pred )\n",
    "\n",
    "# What is accuracy? -> Percent of accurate predictions\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "0.8888888888888888\n",
      "0.8888888888888888\n",
      "[[15  0  0]\n",
      " [ 1 11  1]\n",
      " [ 0  3 14]]\n"
     ]
    }
   ],
   "source": [
    "tree_model =   DecisionTreeClassifier()\n",
    "\n",
    "tree_model.fit(X_train,y_train)\n",
    "\n",
    "tree_pred = tree_model.predict(X_test)\n",
    "\n",
    "# ->  (True Positives + True Negatives) / (True Positives + False Positives + Ture Negatives + False Negatives)\n",
    "accuracy = accuracy_score(y_test,tree_pred  )\n",
    "# True Positives / (True Positives + False Positives) \n",
    "precision = precision_score(y_test, tree_pred,average='micro'  )\n",
    "# True Positives / (True Positives + False Negatives)\n",
    "recall = recall_score(y_test,tree_pred ,average='micro' )\n",
    "\n",
    "confusion = confusion_matrix(y_test,tree_pred  )\n",
    "\n",
    "# What is accuracy? -> Percent of accurate predictions\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n",
      "Precision: 0.9777777777777777\n",
      "Recall: 0.9777777777777777\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 17]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Random_model = RandomForestClassifier()\n",
    "Random_model.fit(X_train, y_train)\n",
    "Random_pred = Random_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, Random_pred)\n",
    "precision = precision_score(y_test, Random_pred, average='micro')\n",
    "recall = recall_score(y_test, Random_pred, average='micro')\n",
    "confusion = confusion_matrix(y_test, Random_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "Confusion Matrix:\n",
      " [[15  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 17]]\n"
     ]
    }
   ],
   "source": [
    "ld_model = LinearDiscriminantAnalysis()\n",
    "ld_model.fit(X_train, y_train)\n",
    "ld_predictions = ld_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, ld_predictions)\n",
    "precision = precision_score(y_test, ld_predictions, average='micro')\n",
    "recall = recall_score(y_test, ld_predictions, average='micro')\n",
    "confusion = confusion_matrix(y_test, ld_predictions)\n",
    "\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Confusion Matrix:\\n\", confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Machines (GBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n",
      "0.9777777777777777\n",
      "0.9777777777777777\n",
      "[[15  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1 16]]\n"
     ]
    }
   ],
   "source": [
    "gb_model =   GradientBoostingClassifier()\n",
    "\n",
    "gb_model .fit(X_train,y_train)\n",
    "\n",
    "gb_pred = gb_model .predict(X_test)\n",
    "\n",
    "# ->  (True Positives + True Negatives) / (True Positives + False Positives + Ture Negatives + False Negatives)\n",
    "accuracy = accuracy_score(y_test,gb_pred   )\n",
    "# True Positives / (True Positives + False Positives) \n",
    "precision = precision_score(y_test,gb_pred ,average='micro'  )\n",
    "# True Positives / (True Positives + False Negatives)\n",
    "recall = recall_score(y_test,gb_pred ,average='micro' )\n",
    "\n",
    "confusion = confusion_matrix(y_test,gb_pred  )\n",
    "\n",
    "# What is accuracy? -> Percent of accurate predictions\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "[[15  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 17]]\n"
     ]
    }
   ],
   "source": [
    "NB_model =   GaussianNB()\n",
    "\n",
    "NB_model .fit(X_train,y_train)\n",
    "\n",
    "NB_pred = NB_model .predict(X_test)\n",
    "\n",
    "# ->  (True Positives + True Negatives) / (True Positives + False Positives + Ture Negatives + False Negatives)\n",
    "accuracy = accuracy_score(y_test,NB_pred   )\n",
    "# True Positives / (True Positives + False Positives) \n",
    "precision = precision_score(y_test,NB_pred ,average='micro'  )\n",
    "# True Positives / (True Positives + False Negatives)\n",
    "recall = recall_score(y_test,NB_pred ,average='micro' )\n",
    "\n",
    "confusion = confusion_matrix(y_test,NB_pred  )\n",
    "\n",
    "# What is accuracy? -> Percent of accurate predictions\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
